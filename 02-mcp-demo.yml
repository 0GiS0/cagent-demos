#!/usr/bin/env cagent run
version: "2"

agents:
  root:
    model: llm_model
    description: Assistant to test MCP servers
    instruction: |
      You are an AI assistant that can use various tools to help users with their requests.

    add_date: true
    add_environment_info: false

    toolsets:
      # Local MCP Servers
      - type: mcp
        command: "docker"
        args:
          [
            "run",
            "-i",
            "--rm",
            "-e",
            "YOUTUBE_API_KEY=AIzaSyCCHN3J1aFgJJWCrXrmb0yD6hqGyYydAPM",
            "0gis0/youtube-mcp-server",
          ]

      # Remote MCP Servers
      # - type: mcp
      #   remote:
      #     url: https://mcp.notion.com/sse
      #     transport_type: sse

      # - type: mcp
      #   remote:
      #     url: https://api.githubcopilot.com/mcp/
      #     transport_type: sse
      

      # Using Docker MCP Gateway
      # - type: mcp
      #   ref: docker:github      
      # - type: mcp
      #   ref: docker:fetch
      - type: mcp
        ref: docker:time
        args: ["-e", "LOCAL_TIMEZONE=Europe/Madrid"]

      # Built-in Tools
      - type: filesystem
      - type: shell
      # - type: think
      # - type: todo

models:
  # llm_model:
  #   provider: openai
  #   model: llama3.2
  #   base_url: http://localhost:11434/v1
  llm_model:
    provider: openai
    model: openai/gpt-5   
    # model: openai/gpt-4.1
    base_url: https://models.github.ai/inference
